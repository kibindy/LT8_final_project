{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2855c16",
   "metadata": {},
   "source": [
    "# Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc37102",
   "metadata": {},
   "source": [
    "## Brief Summary:\n",
    "**Goal**: To use Y-STR markers (Short Tandem Repeats) to predict Y-SNP Haplogroup (Single Nucleotide Polymorphism).\n",
    "\n",
    "**Introduction**: \n",
    "Human Y chromosome is essential for tracing male lineages in forensic anthropology and investigations. It contains important information contained as Y-chromosome Short Tandem Repeats (Y-STRs) and Y-chromosome Single Nucleotide Polymorphism (Y-SNPs).\n",
    "\n",
    "Y-STRs are polymorphic markers routinely used in forensic science due to their male-specific inheritance. \n",
    "\n",
    "Y-SNPs on the other hand are used to predict haplogroups which is a process crucial for narrowing down investigation scopes in forensics.\n",
    "\n",
    "However, predicting Y-SNP haplogroups from Y-STR data often suffers from low resolution with existing online tools.\n",
    "\n",
    "This study addresses this gap by developing machine learning models to offer high-resolution haplogroup prediction by leveraging a robust set of Y-STR data from a study published by Song, *et. al.* in 2024.\n",
    "\n",
    "**Significance**: The contributions from this research could aid in population studies and forensic genetics as it establish machine learning models to produce high-resolution bridge between two major data types. \n",
    "\n",
    "Mapping rapidly mutating Y-STR data to a relatively more stable Y-SNP haplogroups, the these models can transform vast existing, low-resolution forensic datasets into actionable genetic resources. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010cac3e",
   "metadata": {},
   "source": [
    "<i><b>For Jan</b>: Insert business value</i>\n",
    "Note: higher haplogroup resolution = more specific identification, more specific identification = more business value \n",
    "üêÇüêì\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d6fa9",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "The dataset utilized in this project originates from the supplementary material of YHP: Y-chromosome Haplogroup Predictor (Song et al., 2024), which trained machine-learning models to predict Y-SNP haplogroups from Y-STR haplotypes. \n",
    "\n",
    "It contains per-sample Y-STR allele values (using 27 Yfiler Plus Kit loci), population labels, and Y-SNP haplogroup assignments for 4,064 male samples from eight East Asian populations (Han, Hui, Yi, Mongolian, Kyrgyz, Zhuang, Li, Tibetan). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a571f",
   "metadata": {},
   "source": [
    "<i><b>For Jan</b>: Insert write up</i>\n",
    "\n",
    "Note: https://www.sciencedirect.com/science/article/abs/pii/S0379073824001944\n",
    "üêÇüêì\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f6d35",
   "metadata": {},
   "source": [
    "## Main Problem:\n",
    "\n",
    "Can a machine learning model accurately map complex Y-STR profiles to specific, high-resolution Y-SNP haplogroups to transform standard forensic data into actionable genetic intelligence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdacbb8",
   "metadata": {},
   "source": [
    "## Main Problem\n",
    "\n",
    "<i><b>For Jan</b>: Insert main problem</i>\n",
    "\n",
    "Sample: What models can be recommended that provides the highest accuracy depending on the resolution level?\n",
    "üêÇüêì"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b272c9",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9fd51",
   "metadata": {},
   "source": [
    "If there is only 1 sample of a specific haplogroup, we will remove it from the dataset\n",
    "\n",
    "Rationale: There is not enough samples to train the model and classify that specific haplogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667b143f",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b68b63c",
   "metadata": {},
   "source": [
    "Step 1. Identify the Business Problem\n",
    "\n",
    "Step 2. Identify the Machine Learning Task\n",
    "\n",
    "Step 3. Identify Key Evaluation Metrics\n",
    "\n",
    "Step 4. Build and Test Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c2aef",
   "metadata": {},
   "source": [
    "## 1. Identify the Business Problem\n",
    "\n",
    "The core operational problem is the inefficient use of existing forensic data which results to escalated investigative costs. \n",
    "\n",
    "When a forensic lab generates a Y-STR profile, existing prediction tools only provide a low-resolution classification. This failure is a critical operational bottleneck because the resulting lineage is too broad to effectively narrow a suspect pool in familial searching, leading to wasted investigative resources and missed leads. \n",
    "\n",
    "To obtain the necessary high-resolution data, additional more expensive and time-consuming wetlab and dry lab analyses dedicated to Y-SNP sequencing are needed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba893cb",
   "metadata": {},
   "source": [
    "<i><b>For Jan</b>: Rephrase motivation and main problem</i>\n",
    "üêÇüêì\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790c387",
   "metadata": {},
   "source": [
    "## 2. Identify the Machine Learning Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad27763",
   "metadata": {},
   "source": [
    "What will the machine learning model do?\n",
    "- Goal is to predict the class label (i.e. haplogroup) choice from a predefined list of states (i.e. 27 Y-STRs)\n",
    "\n",
    "Classification Problem\n",
    "- Input: Y-STRs\n",
    "- Output: Haplogroups\n",
    "\n",
    "Since this is a classification problem, the following models will be utilized.\n",
    "1. KNN\n",
    "2. SVM\n",
    "3. LDA\n",
    "4. Gaussian Naive Bayes\n",
    "5. Decision Tree\n",
    "6. Random Forest\n",
    "7. Gradient Boosting\n",
    "\n",
    "For KNN, and SVM, scaling will be applied during the data preprocessing to help with faster convergence, equal feature contribution, and improved performance [2][3].\n",
    "\n",
    "Note that Logistic Regression (L1, L2) will not be used because the dataset includes classes (i.e. Haplogroups) that only occur once. One of the limitations of Logistic Regression is that overfitting may occur if the number of observations is less than the number of features [4]. Given the nature of the dataset, the ValueError \"This solver needs samples of at least 2 classes in the data, but the data contains only one class\" was raised, indicating that there are instances where there is insufficient samples for a particular class to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38a92f",
   "metadata": {},
   "source": [
    "## 3. Identify Key Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409836e9",
   "metadata": {},
   "source": [
    "<i><b>For Jan</b>: What evaluation metric will we use? If we will use Accuracy, explain why we will use Accuracy as the evalutation metric.\n",
    "\n",
    "We also need to look for any industry benchmarks on Accuracy. Otherwise, we can proceed to using PCC.</i>\n",
    "\n",
    "Evaluation Metrics: Classification\n",
    "- Accuracy: use when the goal is to minimize the overall error state\n",
    "- Precision: use when the cost of false positives is high\n",
    "- Recall: use when the cost of false negatives is high\n",
    "- F1-score: use if you want to optimize precision and recall at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b7b32",
   "metadata": {},
   "source": [
    "### PCC for Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5bf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54329cfe",
   "metadata": {},
   "source": [
    "## 4. Build and Test Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03e856cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c90a35",
   "metadata": {},
   "source": [
    "### 4.1 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4921b",
   "metadata": {},
   "source": [
    "### 4.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb6e3eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haplogroup</th>\n",
       "      <th>number of haplotypes</th>\n",
       "      <th>haplotype</th>\n",
       "      <th>total frequency</th>\n",
       "      <th>sampleID</th>\n",
       "      <th>population</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[19.0, 14.0, 22.0, 31.0, 22.0, 10.0, 17.0, 16....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLM100</td>\n",
       "      <td>Hulunbuir[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[19.0, 14.0, 22.0, 30.0, 22.0, 10.0, 18.0, 17....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HHM158</td>\n",
       "      <td>Hohhot[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18.0, 14.0, 21.0, 31.0, 24.0, 10.0, 17.0, 16....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ODM030</td>\n",
       "      <td>Ordos[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[19.0, 14.0, 22.0, 30.0, 20.0, 10.0, 18.0, 17....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLM178</td>\n",
       "      <td>Hulunbuir[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O2a2b1a1a1a4a1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[18.0, 12.0, 20.0, 29.0, 19.0, 9.0, 18.0, 14.0...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HHM088</td>\n",
       "      <td>Hohhot[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[20.0, 12.0, 20.0, 28.0, 21.0, 10.0, 15.0, 15....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HaiN153(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18.0, 12.0, 21.0, 28.0, 21.0, 10.0, 17.0, 15....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GD-16(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[19.0, 12.0, 21.0, 28.0, 21.0, 10.0, 18.0, 16....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>JX-82(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[16.0, 14.0, 21.0, 29.0, 22.0, 11.0, 16.0, 15....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HaiN139(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[17.0, 12.0, 21.0, 28.0, 23.0, 10.0, 17.0, 16....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SX-92(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4064 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          haplogroup  number of haplotypes  \\\n",
       "0            C2b1a1a                   4.0   \n",
       "1                NaN                   NaN   \n",
       "2                NaN                   NaN   \n",
       "3                NaN                   NaN   \n",
       "4     O2a2b1a1a1a4a1                   6.0   \n",
       "...              ...                   ...   \n",
       "4059             NaN                   NaN   \n",
       "4060             NaN                   NaN   \n",
       "4061             NaN                   NaN   \n",
       "4062             NaN                   NaN   \n",
       "4063             NaN                   NaN   \n",
       "\n",
       "                                              haplotype  total frequency  \\\n",
       "0     [19.0, 14.0, 22.0, 31.0, 22.0, 10.0, 17.0, 16....              1.0   \n",
       "1     [19.0, 14.0, 22.0, 30.0, 22.0, 10.0, 18.0, 17....              1.0   \n",
       "2     [18.0, 14.0, 21.0, 31.0, 24.0, 10.0, 17.0, 16....              1.0   \n",
       "3     [19.0, 14.0, 22.0, 30.0, 20.0, 10.0, 18.0, 17....              1.0   \n",
       "4     [18.0, 12.0, 20.0, 29.0, 19.0, 9.0, 18.0, 14.0...              1.0   \n",
       "...                                                 ...              ...   \n",
       "4059  [20.0, 12.0, 20.0, 28.0, 21.0, 10.0, 15.0, 15....              1.0   \n",
       "4060  [18.0, 12.0, 21.0, 28.0, 21.0, 10.0, 17.0, 15....              1.0   \n",
       "4061  [19.0, 12.0, 21.0, 28.0, 21.0, 10.0, 18.0, 16....              1.0   \n",
       "4062  [16.0, 14.0, 21.0, 29.0, 22.0, 11.0, 16.0, 15....              1.0   \n",
       "4063  [17.0, 12.0, 21.0, 28.0, 23.0, 10.0, 17.0, 16....              1.0   \n",
       "\n",
       "          sampleID            population  frequency  \n",
       "0           HLM100  Hulunbuir[Mongolian]        1.0  \n",
       "1           HHM158     Hohhot[Mongolian]        1.0  \n",
       "2           ODM030      Ordos[Mongolian]        1.0  \n",
       "3           HLM178  Hulunbuir[Mongolian]        1.0  \n",
       "4           HHM088     Hohhot[Mongolian]        1.0  \n",
       "...            ...                   ...        ...  \n",
       "4059  HaiN153(Han)                   Han        1.0  \n",
       "4060    GD-16(Han)                   Han        1.0  \n",
       "4061    JX-82(Han)                   Han        1.0  \n",
       "4062  HaiN139(Han)                   Han        1.0  \n",
       "4063    SX-92(Han)                   Han        1.0  \n",
       "\n",
       "[4064 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1. Load dataset\n",
    "df = pd.read_excel('Supplemental Processed Data Set.xlsx', sheet_name='S Table 1', skiprows=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4c880db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haplogroup</th>\n",
       "      <th>number of haplotypes</th>\n",
       "      <th>haplotype</th>\n",
       "      <th>total frequency</th>\n",
       "      <th>sampleID</th>\n",
       "      <th>population</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[19.0, 14.0, 22.0, 31.0, 22.0, 10.0, 17.0, 16....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLM100</td>\n",
       "      <td>Hulunbuir[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[19.0, 14.0, 22.0, 30.0, 22.0, 10.0, 18.0, 17....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HHM158</td>\n",
       "      <td>Hohhot[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[18.0, 14.0, 21.0, 31.0, 24.0, 10.0, 17.0, 16....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ODM030</td>\n",
       "      <td>Ordos[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[19.0, 14.0, 22.0, 30.0, 20.0, 10.0, 18.0, 17....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLM178</td>\n",
       "      <td>Hulunbuir[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O2a2b1a1a1a4a1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[18.0, 12.0, 20.0, 29.0, 19.0, 9.0, 18.0, 14.0...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HHM088</td>\n",
       "      <td>Hohhot[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[20.0, 12.0, 20.0, 28.0, 21.0, 10.0, 15.0, 15....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HaiN153(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[18.0, 12.0, 21.0, 28.0, 21.0, 10.0, 17.0, 15....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GD-16(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[19.0, 12.0, 21.0, 28.0, 21.0, 10.0, 18.0, 16....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>JX-82(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[16.0, 14.0, 21.0, 29.0, 22.0, 11.0, 16.0, 15....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HaiN139(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[17.0, 12.0, 21.0, 28.0, 23.0, 10.0, 17.0, 16....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SX-92(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4064 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          haplogroup  number of haplotypes  \\\n",
       "0            C2b1a1a                   4.0   \n",
       "1            C2b1a1a                   4.0   \n",
       "2            C2b1a1a                   4.0   \n",
       "3            C2b1a1a                   4.0   \n",
       "4     O2a2b1a1a1a4a1                   6.0   \n",
       "...              ...                   ...   \n",
       "4059      O2a1c1a1a1                  14.0   \n",
       "4060      O2a1c1a1a1                  14.0   \n",
       "4061      O2a1c1a1a1                  14.0   \n",
       "4062      O2a1c1a1a1                  14.0   \n",
       "4063      O2a1c1a1a1                  14.0   \n",
       "\n",
       "                                              haplotype  total frequency  \\\n",
       "0     [19.0, 14.0, 22.0, 31.0, 22.0, 10.0, 17.0, 16....              1.0   \n",
       "1     [19.0, 14.0, 22.0, 30.0, 22.0, 10.0, 18.0, 17....              1.0   \n",
       "2     [18.0, 14.0, 21.0, 31.0, 24.0, 10.0, 17.0, 16....              1.0   \n",
       "3     [19.0, 14.0, 22.0, 30.0, 20.0, 10.0, 18.0, 17....              1.0   \n",
       "4     [18.0, 12.0, 20.0, 29.0, 19.0, 9.0, 18.0, 14.0...              1.0   \n",
       "...                                                 ...              ...   \n",
       "4059  [20.0, 12.0, 20.0, 28.0, 21.0, 10.0, 15.0, 15....              1.0   \n",
       "4060  [18.0, 12.0, 21.0, 28.0, 21.0, 10.0, 17.0, 15....              1.0   \n",
       "4061  [19.0, 12.0, 21.0, 28.0, 21.0, 10.0, 18.0, 16....              1.0   \n",
       "4062  [16.0, 14.0, 21.0, 29.0, 22.0, 11.0, 16.0, 15....              1.0   \n",
       "4063  [17.0, 12.0, 21.0, 28.0, 23.0, 10.0, 17.0, 16....              1.0   \n",
       "\n",
       "          sampleID            population  frequency  \n",
       "0           HLM100  Hulunbuir[Mongolian]        1.0  \n",
       "1           HHM158     Hohhot[Mongolian]        1.0  \n",
       "2           ODM030      Ordos[Mongolian]        1.0  \n",
       "3           HLM178  Hulunbuir[Mongolian]        1.0  \n",
       "4           HHM088     Hohhot[Mongolian]        1.0  \n",
       "...            ...                   ...        ...  \n",
       "4059  HaiN153(Han)                   Han        1.0  \n",
       "4060    GD-16(Han)                   Han        1.0  \n",
       "4061    JX-82(Han)                   Han        1.0  \n",
       "4062  HaiN139(Han)                   Han        1.0  \n",
       "4063    SX-92(Han)                   Han        1.0  \n",
       "\n",
       "[4064 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2. Fill NaN values\n",
    "df = df.ffill()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "742f8b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haplogroup</th>\n",
       "      <th>number of haplotypes</th>\n",
       "      <th>total frequency</th>\n",
       "      <th>sampleID</th>\n",
       "      <th>population</th>\n",
       "      <th>frequency</th>\n",
       "      <th>DYS576</th>\n",
       "      <th>DYS389 I</th>\n",
       "      <th>DYS635</th>\n",
       "      <th>DYS389 II</th>\n",
       "      <th>...</th>\n",
       "      <th>DYS437</th>\n",
       "      <th>DYS385a</th>\n",
       "      <th>DYS385b</th>\n",
       "      <th>DYS449</th>\n",
       "      <th>DYS393</th>\n",
       "      <th>DYS439</th>\n",
       "      <th>DYS481</th>\n",
       "      <th>DYS576a</th>\n",
       "      <th>DYS576b</th>\n",
       "      <th>DYS533</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLM100</td>\n",
       "      <td>Hulunbuir[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HHM158</td>\n",
       "      <td>Hohhot[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ODM030</td>\n",
       "      <td>Ordos[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C2b1a1a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLM178</td>\n",
       "      <td>Hulunbuir[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O2a2b1a1a1a4a1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HHM088</td>\n",
       "      <td>Hohhot[Mongolian]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HaiN153(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GD-16(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>JX-82(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HaiN139(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>O2a1c1a1a1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SX-92(Han)</td>\n",
       "      <td>Han</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4064 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          haplogroup  number of haplotypes  total frequency      sampleID  \\\n",
       "0            C2b1a1a                   4.0              1.0        HLM100   \n",
       "1            C2b1a1a                   4.0              1.0        HHM158   \n",
       "2            C2b1a1a                   4.0              1.0        ODM030   \n",
       "3            C2b1a1a                   4.0              1.0        HLM178   \n",
       "4     O2a2b1a1a1a4a1                   6.0              1.0        HHM088   \n",
       "...              ...                   ...              ...           ...   \n",
       "4059      O2a1c1a1a1                  14.0              1.0  HaiN153(Han)   \n",
       "4060      O2a1c1a1a1                  14.0              1.0    GD-16(Han)   \n",
       "4061      O2a1c1a1a1                  14.0              1.0    JX-82(Han)   \n",
       "4062      O2a1c1a1a1                  14.0              1.0  HaiN139(Han)   \n",
       "4063      O2a1c1a1a1                  14.0              1.0    SX-92(Han)   \n",
       "\n",
       "                population  frequency DYS576 DYS389 I DYS635 DYS389 II  ...  \\\n",
       "0     Hulunbuir[Mongolian]        1.0   19.0     14.0   22.0      31.0  ...   \n",
       "1        Hohhot[Mongolian]        1.0   19.0     14.0   22.0      30.0  ...   \n",
       "2         Ordos[Mongolian]        1.0   18.0     14.0   21.0      31.0  ...   \n",
       "3     Hulunbuir[Mongolian]        1.0   19.0     14.0   22.0      30.0  ...   \n",
       "4        Hohhot[Mongolian]        1.0   18.0     12.0   20.0      29.0  ...   \n",
       "...                    ...        ...    ...      ...    ...       ...  ...   \n",
       "4059                   Han        1.0   20.0     12.0   20.0      28.0  ...   \n",
       "4060                   Han        1.0   18.0     12.0   21.0      28.0  ...   \n",
       "4061                   Han        1.0   19.0     12.0   21.0      28.0  ...   \n",
       "4062                   Han        1.0   16.0     14.0   21.0      29.0  ...   \n",
       "4063                   Han        1.0   17.0     12.0   21.0      28.0  ...   \n",
       "\n",
       "     DYS437 DYS385a DYS385b DYS449 DYS393 DYS439 DYS481 DYS576a DYS576b DYS533  \n",
       "0      14.0    11.0    19.0   30.0   14.0   12.0   24.0    36.0    39.0   12.0  \n",
       "1      14.0    11.0    17.0   30.0   14.0   14.0   24.0    39.0    39.0   12.0  \n",
       "2      14.0    11.0    19.0   30.0   14.0   12.0   23.0    37.0    38.0   12.0  \n",
       "3      14.0    11.0    17.0   30.0   14.0   14.0   24.0    39.0    39.0   12.0  \n",
       "4      16.0    14.0    18.0   32.0   11.0   13.0   23.0    35.0    37.0   11.0  \n",
       "...     ...     ...     ...    ...    ...    ...    ...     ...     ...    ...  \n",
       "4059   14.0    13.0    13.0   31.0   13.0   11.0   25.0    37.0    40.0   11.0  \n",
       "4060   14.0    12.0    19.0   31.0   12.0   12.0   28.0    36.0    38.0   11.0  \n",
       "4061   14.0    12.0    19.0   33.0   12.0   12.0   26.0    36.0    39.0   11.0  \n",
       "4062   14.0    12.0    18.0   29.0   14.0   12.0   23.0    37.0    39.0   11.0  \n",
       "4063   14.0    12.0    19.0   31.0   12.0   11.0   27.0    36.0    38.0   11.0  \n",
       "\n",
       "[4064 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3. Split haplotype into separate columns\n",
    "df = pd.concat([df, df['haplotype'].str.replace('[', '').str.replace(']', '').str.split(',', expand=True)], axis=1)\n",
    "YSTRs = {0: \"DYS576\", 1: \"DYS389 I\", 2: \"DYS635\", 3: \"DYS389 II\", 4: \"DYS627\", 5: \"DYS460\", 6: \"DYS458\",\n",
    "                 7: \"DYS19\", 8: \"Y-GATA-H4\", 9: \"DYS448\", 10: \"DYS391\", 11: \"DYS456\", 12: \"DYS390\", 13: \"DYS438\", \n",
    "                 14: \"DYS392\", 15: \"DYS518\", 16: \"DYS570\", 17: \"DYS437\", 18: \"DYS385a\", 19: \"DYS385b\", 20: \"DYS449\", \n",
    "                 21: \"DYS393\", 22: \"DYS439\", 23: \"DYS481\", 24: \"DYS576a\", 25: \"DYS576b\", 26: \"DYS533\"\n",
    "}\n",
    "\n",
    "df = df.rename(columns=YSTRs)\n",
    "df = df.drop(columns=['haplotype'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda5aace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25 PCC: 0.0140\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Use PCC for benchmark\n",
    "\n",
    "haplogroup_df = pd.DataFrame(df['haplogroup'].value_counts())\n",
    "haplogroup_df['proportions'] = haplogroup_df['count'] / (haplogroup_df['count'].sum())\n",
    "haplogroup_df['proportions^2'] = haplogroup_df['proportions']**2\n",
    "pcc = haplogroup_df['proportions^2'].sum()\n",
    "pcc_125 = pcc*1.25\n",
    "print(f'1.25 PCC: {pcc_125:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39738b37",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153b3bf",
   "metadata": {},
   "source": [
    "Note:\n",
    "- GBM is prone to overfitting\n",
    "- Consider doing a confusion matrix?? For random forest, check where mistakes/confusions were made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbc9d4",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df898d23",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf9c85",
   "metadata": {},
   "source": [
    "[1] https://www.sciencedirect.com/science/article/abs/pii/S0379073824001944\n",
    "\n",
    "[2] https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35/#:~:text=IN%20DEPTH%20ANALYSIS,scaling%20in%20the%20X%2DY%20plane.\n",
    "\n",
    "[3] https://www.geeksforgeeks.org/machine-learning/Feature-Engineering-Scaling-Normalization-and-Standardization/\n",
    "\n",
    "[4] https://www.geeksforgeeks.org/data-science/advantages-and-disadvantages-of-logistic-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ff653",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6f14d9d",
   "metadata": {},
   "source": [
    "### Sample Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5a1d6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
